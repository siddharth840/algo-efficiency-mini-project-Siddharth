ğŸ”¥ Project Overview

The goal of this mini-project is to implement multiple algorithms, analyze their performance, and visualize their execution time behaviour as the input size increases.

Algorithms that solve the same problem can differ dramatically in performance based on design choices such as recursion, iteration, and partitioning strategies.
This project helps understand those trade-offs through real experimental profiling.

ğŸ§  Algorithms Implemented
Algorithm	Type	Notes
Fibonacci (Naive Recursive)	Recursive	Exponential time
Fibonacci (Dynamic Programming)	Bottom-Up	Linear time
Merge Sort	Divide & Conquer	Guaranteed O(n log n)
Quick Sort	Divide & Conquer	Very fast, but worst case O(nÂ²)
Insertion Sort	Comparison-Based	Efficient for nearly-sorted data
Bubble Sort	Comparison-Based	Slow for large datasets
Selection Sort	Comparison-Based	Consistent O(nÂ²)
Binary Search	Searching	Requires sorted input
ğŸ§ª Performance Profiling

For each algorithm:

âœ” Execution time measured using time.perf_counter()
âœ” Repeated runs to reduce random variation
âœ” Results plotted using matplotlib

Input Size Strategy
Class	Algorithms	Input Sizes
O(n log n)	Merge Sort, Quick Sort	100 â†’ 10,000
O(nÂ²)	Insertion, Bubble, Selection	100 â†’ 2,000
Exponential	Fibonacci (Recursive)	5 â†’ 30
O(log n)	Binary Search	100 â†’ 10,000
O(n)	Fibonacci (DP)	1000 â†’ 10,000
ğŸ“Š Output & Visualizations

The notebook generates:

ğŸ“Œ execution_time_plots.png
A combined figure showing timing curves for:

n log n algorithms

nÂ² algorithms

Binary Search

Fibonacci (Recursive vs DP)

The plot clearly shows how algorithms diverge in efficiency as the input grows.

ğŸ“ˆ Key Insights & Findings

ğŸ”¹ Algorithms with O(n log n) complexity scale efficiently and remain practical for large inputs
ğŸ”¹ O(nÂ²) algorithms become significantly slower as input size increases
ğŸ”¹ Binary Search time per query is extremely small due to logarithmic growth
ğŸ”¹ Recursive Fibonacci grows exponentially and becomes infeasible beyond n â‰ˆ 30
ğŸ”¹ Dynamic Programming Fibonacci is highly efficient and can handle large n easily

ğŸš€ Repository Contents (recommended structure)
algo-efficiency-mini-project-<yourname>/
â”‚
â”œâ”€â”€ algo_analysis_notebook.ipynb
â”œâ”€â”€ execution_time_plots.png
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore

â–¶ How to Run the Notebook
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Run the notebook
jupyter notebook algo_analysis_notebook.ipynb


No external datasets are required â€” the notebook generates random input lists automatically.

ğŸ“š Citations & References

CLRS â€“ Introduction to Algorithms

Python Documentation â€“ time, memory_profiler, and matplotlib

ğŸ™Œ Acknowledgement

This project was completed as part of Design and Analysis of Algorithms Lab (ENCA351) in the School of Engineering & Technology, K.R. Mangalam University.

ğŸ‰ README COMPLETE

Let me know if you want:
ğŸ”¸ requirements.txt + .gitignore
ğŸ”¸ converting notebook code into separate .py files
ğŸ”¸ exporting the project into a ZIP folder
ğŸ”¸ submitting a GitHub-ready folder automatically
